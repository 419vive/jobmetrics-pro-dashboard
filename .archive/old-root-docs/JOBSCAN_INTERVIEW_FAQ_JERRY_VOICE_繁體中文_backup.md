# Jobscan 面試 - 20 個常見問題（Jerry 真實語氣版）

**候選人**：賴和鉅（Jerry Lai）
**職位**：Jobscan 資深數據分析師
**主要專案**：JobMetrics Pro 儀表板

---

## 問題 1：請介紹一下你自己以及你在數據分析方面的背景。

**答案（< 60 秒）：**

「嘿，謝謝今天給我機會。我是 Jerry，做數據分析三年了，但我背景有點特別。我是從數位行銷出身的，所以我不只是建模型，我會想這個東西到底能不能推動業務。就是，我在乎最後那個收入數字。

我擅長三件事。第一，我會預測誰快要走了。建了模型攔下 5 萬人不讓他們流失，賺回 240 萬美金。第二，我不只做分析，我做系統。欺詐檢測跑在生產環境、供應鏈處理百萬筆記錄、醫生真的在用的醫療 AI。第三，我讓數據變得好用。自助式儀表板、AI 助手，這樣大家就不用每五分鐘煩一次數據團隊。把例行查詢砍掉 80%。

職涯的話，從 Nike Taiwan 開始——那時候被數據吸引住了。然後 Farmz Asia，把留存推高 35%。CAE，每天處理 1200 萬美金的交易分析。技術上用 Python、SQL、機器學習、Tableau。現在在學 BigQuery。GitHub 上有 19 個專案——從 SaaS 儀表板到流失模型到碳計算器。都是能真的跑、真的創造價值的東西。

然後你看——我特別為你們做了 JobMetrics Pro。不是 demo，是證明我懂 Jobscan 要什麼，第一天就能上。」

---

## 問題 2：JobMetrics Pro 可以追蹤哪些具體指標和洞察？

**答案（< 60 秒）：**

「好，JobMetrics Pro 追蹤的是你們 SaaS 真正需要的東西。收入指標——MRR、成長率、ARPU、按方案的細分。就是那些錢的數字。客戶經濟——CAC、LTV、還有 LTV 比 CAC 的比率。我 demo 裡是 66 倍，超誇張的，但重點是你至少要 3 倍以上。白話文就是，你花一塊錢拿客戶，要賺回至少三塊，不然生意做不下去。

產品面——履歷匹配率、掃描量、掃描要多久。基本上就是人們怎麼用你 ATS 功能的所有事情。參與度——日活、週活、月活、留存、流失預測。這些。

但讓它好用的是這個。有個轉換漏斗直接告訴你人在哪裡跑掉——註冊到第一次掃描到付費客戶。你馬上看到流失點在哪。白話文就是，你知道哪個環節在漏錢，就去修那個環節。還有按註冊月份的同期群分析，所以你能提早抓到問題。像如果九月註冊的人比八月死得快，你就知道有東西變了。

所有東西都是即時的。背景還跑著異常檢測標記奇怪的事——比如 MRR 突然掉 20%，它會警告你。白話文就是，系統幫你盯著，不用你每天手動檢查數字有沒有炸掉。因為那八成是數據管道問題，不是真的業務問題。」

---

## 問題 3：你的儀表板中的 AI 組件是怎麼運作的？

**答案（< 60 秒）：**

「AI 助手——老實說是我最喜歡的部分。它跑 Claude API，3.5 Sonnet 那個模型。為什麼重要？因為任何人都能用正常的中文或英文問問題。『流失率是什麼在推動的？』『哪個渠道 ROI 最好？』AI 會讀你實際的儀表板數據，分析它，給你有上下文的答案。不只是數字——它會說『你的流失率是 0.38%，跟業界標準的 5% 比超好，這代表產品市場契合度強。』

所以你 PM 或你 CEO 不用去 Slack 數據團隊然後等兩天。他們馬上得到答案。白話文就是，數據團隊不用再當客服，可以做真正重要的事。還有個自動洞察的東西每週跑一次——浮出你該在意的前三到五個模式。加上給新人的指標解釋器，那些不知道 LTV 比 CAC 是什麼的人。

大局是？它把那些例行的『我的流失率多少』問題砍掉 80%。數據團隊可以專注做真正有戰略價值的工作，不用當人肉查詢機器人。」

---

## 問題 4：為什麼你選擇在分析儀表板中整合 AI？

**答案（< 60 秒）：**

「因為我在工作過的每家公司都看到一樣的問題。利益相關者花 40% 的時間在要報告。數據團隊變成瓶頸。大家都慢下來。白話文就是，等數據變成常態，等的時候商機就跑掉了。

AI 解決這個。非技術人員可以問問題不用懂 SQL。不用等分析師處理你的 ticket。而且它幹掉那些基本重複問題——『我流失率多少』——砍 80%，意思是數據團隊可以做真正有價值的工作。預測模型、實驗、新功能。不只是拉數字。

對你們 Jobscan 來說更重要，因為你資料散得到處都是——Stripe、Google Analytics、Ads、MySQL、聯盟網絡。AI 可以從這些來源全部拉資料然後整合。一個答案，多個數據點。白話文就是，不用開五個系統查五次，一次問就全部搞定。

成本？一次查詢一到三美分。就算每天 100 次查詢也才九塊美金一個月。跟你付分析師一小時的錢比？基本上免費。」

---

## 問題 5：告訴我 JobMetrics Pro 背後的數據架構。

**答案（< 60 秒）：**

「一開始就做成模組化、生產就緒的。核心分析引擎用 Python 處理所有指標計算。獨立的 AI 模組跟 Claude API 溝通。配置系統集中管理閾值。Streamlit 前端把這些串起來。白話文就是，每塊各自獨立，要改哪塊不會動到其他塊，維護超方便。

數據處理——Pandas 和 NumPy 做重活。Plotly 做互動圖表。SciPy 做統計像異常檢測。數據模型有用戶、訂閱、掃描、收入——都用外鍵正確連起來。

我還做了個數據生成器創建真實的 SaaS 數據，用正確的分佈。指數分佈做時間到事件的東西，貝塔分佈做匹配率，泊松分佈做關鍵詞計數。所以行為像真實數據。白話文就是，假數據也要像真的，不然測試沒意義。

所有東西都用 Streamlit 的裝飾器快取，所以就算大資料集也很快。對，我還寫了文檔——10 個不同的文檔涵蓋用戶指南、技術內容、API 參考。任何人都能跳進來搞懂。」

---

## 問題 6：你會如何擴展這個儀表板來處理 Jobscan 的實際數據量？

**答案（< 60 秒）：**

「現在它用 CSV 處理大概 10 萬用戶。200 萬用戶？我們得升級堆疊，但邏輯保持一樣因為我做成模組化的。白話文就是，換引擎不用重造車子。

第一，把 CSV 換成 PostgreSQL，在 user ID、訂閱日期、掃描日期上做好索引。這給你規模化的可靠查詢。第二，加 Redis 快取預先計算的東西——每日 MRR、流失率。所以不用每次頁面載入都重算。白話文就是，算過一次的東西記下來，不用一直重算浪費時間。

第三，Celery 做異步處理。重的東西像同期群分析或 AI 洞察在背景跑，不卡 UI。白話文就是，重工作在後台慢慢跑，前台不會卡住讓用戶等。第四，分區數據。按月或季度拆收入和掃描表，所以查詢只碰相關數據。

最後，CDN 放靜態資源，可能把視覺化渲染移到獨立服務。但重點是——業務邏輯不變。分析計算完全一樣。我們只是在下面換數據層。這就是為什麼模組化架構重要。」

---

## 問題 7：你交付過最有影響力的分析專案是什麼？

**答案（< 60 秒）：**

「電信的流失預測。我分析了 110 萬筆客戶交易，建了個模型在人們流失前 30 天抓到他們。85% 準確率。但模型不是厲害的地方——是之後發生的事。

我不只說『這些是高風險客戶』。我說『這是為什麼他們高風險，這是每個群體的干預方法』。有些需要更好的入門。有些需要功能教育。有些需要價格對話。我們攔下 50,738 個人不讓他們走。賺回 25.6 萬美金，ROI 249%。白話文就是，花一塊錢做留存活動，賺回兩塊半。

那個專案教我一件事。早期偵測加自動警報加個人化行動——這個組合對 SaaS 來說是改變遊戲規則的。你不是在人走了之後反應。你是在他們開始出現跡象時就抓到。白話文就是，等人走了再挽回太晚了，要在他們腳還沒跨出門時就抓住。這就是為什麼我把同樣邏輯放進 JobMetrics Pro。因為我知道它有效。」

---

## 問題 8：你是如何識別那些流失模式的？

**答案（< 60 秒）：**

「先做很多特徵工程。登錄頻率、掃描使用、距上次活動天數、功能採用、支援工單、支付歷史。但也有滾動窗口特徵——像『7 天掃描速度』或『30 天參與趨勢』。這些比靜態計數更能捕捉動量變化。白話文就是，不只看他現在怎樣，還要看他最近在變好還是變壞。

然後聚類——K-means 和層次聚類——找出 8 個不同的用戶角色。每個角色有不同風險因素。訓練幾個模型——邏輯迴歸、隨機森林、梯度提升。梯度提升在召回率上贏了，這重要因為我想抓到所有高風險的人。白話文就是，寧可多抓一些沒問題的，也不能漏掉真的要走的人。

然後 SHAP 值做可解釋性。哪些特徵在推動每個用戶的預測。這直接告訴我留存策略該怎麼做。還有時間序列交叉驗證確保它在生產環境真的能跑。

整個東西自動化。每天產生新預測，餵進留存工作流程。」

---

## 問題 9：你會在 Jobscan 首先整合哪些數據源？

**答案（< 60 秒）：**

「從 Stripe 開始。那是你的收入真相——訂閱、MRR、流失事件、支付失敗。所有 SaaS 指標的基礎。白話文就是，錢從哪來、去哪裡，這是第一優先。

然後 Google Analytics 和 Segment 拿用戶行為——頁面流程、轉換漏斗、會話數據。然後你的 MySQL 資料庫拿產品使用——掃描量、匹配率、關鍵詞提取。那是你價值主張的獨特部分。

Google Ads 和聯盟網絡接著來，做 CAC 追蹤和渠道歸因。哪些渠道帶來最好的長期客戶價值。白話文就是，搞清楚哪個行銷管道最划算，把預算放那邊。

這些進來後，我會建一個統一的用戶旅程模型連接所有接觸點。所以你看到完整生命週期——『這用戶來自自然流量，掃了 5 份履歷，看到 LinkedIn 功能後轉成付費，活躍 6 個月了』。那個完整畫面。白話文就是，你知道一個客戶從頭到尾的完整故事，不是片段拼圖。

架構上，可能 ELT 管道用 BigQuery 當倉庫，dbt 做轉換，分析層在上面從那個單一真相來源拉資料。」

---

## 問題 10：你如何處理數據質量和準確性？

**答案（< 60 秒）：**

「多層防護。輸入驗證先來——在資料進資料庫前的攝取點檢查數據類型、範圍、空值、重複。業務邏輯驗證——確保 MRR 跟活躍訂閱匹配，流失計算跟訂閱變化對齊。交叉參考應該講同一個故事的指標。白話文就是，不同數字要對得起來，不能收入說一套、訂閱數說另一套。

每個計算函數都自動測試。特別是複雜的像 LTV 比 CAC 或同期群留存。數據質量監控——『如果 MRR 日環比掉 20%，警告我』因為那八成是管道問題，不是真的業務問題。白話文就是，數字突然炸掉通常是系統壞了，不是業務真的爆了。

定期審計比對儀表板指標和來源系統。像我們的 MRR 計算跟 Stripe 報告對帳。還有文檔化——每個指標都有清楚的定義和公式。沒有模糊空間。

在 JobMetrics Pro 我內建了異常檢測自動標記超出正常閾值的指標。同樣邏輯用在生產環境的數據質量監控。」

---

## 問題 11：告訴我你在數據視覺化方面的經驗。

**答案（< 60 秒）：**

「視覺化是數據變成可行動的地方。我用過 Tableau、Power BI、Plotly、Seaborn——全系列。在 JobMetrics Pro 我用 Plotly 因為它互動。用戶可以懸停、縮放、過濾。讓探索變自然。

關鍵原則——視覺化要配洞察。時間趨勢？折線圖。構成？堆疊柱狀圖或圓餅圖。關係？散點圖。分佈？直方圖。同期群留存？熱力圖。

但也是設計。有意義地用顏色。最小化圖表雜亂。清楚的軸。加上下文像基準線或目標閾值。

JobMetrics Pro 的轉換漏斗——顯示完整用戶旅程加群體和渠道細分。利益相關者立刻看到不同群體在哪掉出來。還有同期群熱力圖深色代表更好留存——就算非技術人員也能讀懂。目標永遠是讓洞察顯而易見，不要埋在裡面。」

---

## 問題 12：為什麼 JobMetrics Pro 與 Jobscan 特別相關？

**答案（< 60 秒）：**

「就像我已經在你團隊裡做的。領域對齊——我在追蹤履歷匹配率、掃描量、關鍵詞提取。所有 ATS 優化的產品指標。商業模式反映你們的免費增值漏斗——免費用戶、掃描行為、轉成付費、訂閱層級、按方案的留存。正是你需要優化的。

自助服務理念直接解決你提到的——減少例行查詢，讓利益相關者自己拿資料。這是整個儀表板的核心價值主張。

AI 助手因為我知道你數據團隊可能被淹沒了。所有 SaaS 經濟學——MRR、CAC、LTV、流失——因為這對訂閱業務很重要。多源整合處理你在面對的——Stripe、GA、Ads、聯盟網絡、產品資料庫——把所有東西拉進一個視圖。

如果我明天加入，我基本上會複製這個但接上你們真實的資料。」

---

## 問題 13：你如何進行利益相關者溝通？

**答案（< 60 秒）：**

「永遠從商業問題開始，不是數據。有人要報告時，我會先釐清——你在做什麼決定？這讓我專注在重要的洞察，不是數據傾倒。

針對受眾調整。高層得到底線——『流失升 2%，原因是這個,解法是這個』——儀表板有三個關鍵指標。PM 得到更深——『這是在推動流失的群體，他們的行為模式，該解決的功能缺口』。工程師得到數據和方法論。

用視覺化講故事。註解、基準線、標註。讓『所以呢』很明顯。用好懂的方式寫所有文檔——這就是為什麼我在 JobMetrics Pro 做了指標解釋器。自助理解。

創建反饋循環。交付分析後，追蹤——這有幫你做決定嗎？你還需要什麼？這建立信任。你在解決問題，不是產生報告。在 Farmz Asia 這方法幫我把留存推高 35% 因為我不只是報告——我在跟團隊合作採取行動。」

---

## 問題 14：你在 SQL 和數據查詢方面有什麼經驗？

**答案（< 60 秒）：**

「從多個職位來的紮實 SQL。在 SUM 二手車公司，用 MySQL、PostgreSQL、MSSQL——複雜查詢做網站性能、轉換漏斗、用戶行為。從基本 SELECT 到複雜 join、窗口函數、CTE、子查詢、聚合都沒問題。

像計算月度留存同期群需要窗口函數像 LAG 和 LEAD 來比較跨期間的用戶活動。流失分析用 CTE 逐步建邏輯——識別訂閱、標記取消、按群體算比率。

也知道怎麼優化。適當的索引、避免 SELECT 星號、理解執行計劃、分區大表。

在 JobMetrics Pro，雖然我 demo 用 Pandas，但分析邏輯直接翻譯成 SQL。同期群分析、漏斗轉換、MRR 計算——底層都是 SQL 操作。現在在提升 BigQuery 因為那是現代倉庫在走的方向。在 Jobscan 我會結合 SQL 提取跟 Python 做複雜轉換和 ML。」

---

## 問題 15：帶我了解你的同期群留存分析。

**答案（< 60 秒）：**

「同期群分析是理解長期用戶行為最強大的工具之一。在 JobMetrics Pro——我按註冊月份把用戶分成同期群。追蹤每個同期群隨時間的留存。第 0 個月永遠是 100% 因為那是註冊。然後測量多少人在第 1、2、3 個月還活著等等。

輸出是個留存熱力圖。每行是個註冊月份，每列是註冊後的時間。顏色顯示留存率——深色代表更好留存。這立刻顯示模式。如果某個同期群留存異常低，你去調查。那個月產品改了？壞的獲客渠道？定價實驗？

第一個月留存特別有價值。它是長期客戶價值的領先指標。如果用戶第 1 個月後還留著，他們更可能變長期客戶。

在 Farmz Asia，同期群分析顯示第一週完成三個特定動作的用戶留存高 70%。完全改變我們的入門流程。對 Jobscan 我會按註冊同期群、方案類型、獲客渠道追蹤留存。找哪些群體有最高終身價值。」

---

## 問題 16：你在 Jobscan 的前 90 天會建立什麼？

**答案（< 60 秒）：**

「前 30 天——學習和打基礎。理解你們目前的數據基礎設施。數據在哪、怎麼流動、利益相關者用什麼報告、痛點在哪。訪談關鍵人物——產品、行銷、客戶成功、財務。他們想回答什麼問題、什麼慢或缺失。審核現有指標定義確保團隊間計算一致。

第 30 到 60 天——開始建。優先事項一，核心 SaaS 指標儀表板——MRR、流失、CAC、LTV。大家需要的心跳指標。先整合 Stripe 和產品資料庫。優先事項二，轉換漏斗分析。直接影響成長——免費到付費旅程、用戶��哪掉、哪些功能推動轉換。優先事項三，帶警報的自動異常檢測。主動抓問題。

第 60 到 90 天——加留存和同期群分析。開始建預測流失模型。實施自助用的 AI 查詢介面。第 90 天時，利益相關者有所有關鍵指標的即時訪問，數據團隊的例行查詢負載大幅下降。」

---

## 問題 17：你如何保持對數據科學和分析趨勢的了解？

**答案（< 60 秒）：**

「對持續學習很有意識。第一，我做專案像 JobMetrics Pro。做東西逼你深度學習。最近整合 Claude API 保持對 LLM 在分析應用的了解。

現在在完成 Google Cloud 的 BigQuery 認證因為那是企業倉儲在走的方向。在 LinkedIn 和 Twitter 追蹤業界領袖——Mode 的 Benn Stancil、dbt 的 Tristan Handy。他們分享現代數據棧的真實世界洞察。

讀 Amplitude、Mixpanel、Looker 的案例研究關於如何大規模解決分析挑戰。參與線上社群——Reddit 數據科學、Stack Overflow、GitHub。問問題也幫助別人因為教學加深理解。

在副專案實驗新工具。現在在學 dbt 做轉換建模,測試 Dagster 做編排。CalTech 訓練營給我基礎，但真正學習是透過做和保持好奇。在 Jobscan 我會帶一樣的心態——持續找更好的方法。」

---

## 問題 18：告訴我一次你必須向非技術利益相關者解釋複雜數據的經歷。

**答案（< 60 秒）：**

「在 CAE，資本資產交易職位。得向零數據背景的高層領導解釋交易量模式和異常檢測。他們看到每天數十萬筆交易值 1200 萬美金，需要理解風險在哪。

不能給他們看迴歸輸出或統計閾值。所以我做了簡單的紅黃綠儀表板。綠色代表『一切正常』。黃色代表『輕微偏差，監控』。紅色代表『立即關注』。每個警報都有白話解釋——『交易量比典型週一高 30%，可能因為市場事件 X』。

完全避開行話。與其說『距平均值三個標準差』，我會說『這在正常情況下幾乎不會發生』。永遠包含『所以呢』——不只『交易量高』而是『高交易量可能代表定價機會或風險暴露，這是該檢查的』。

把他們決策時間減少 70% 因為他們不是淹沒在數據裡。他們有清楚的信號和上下文。這就是 JobMetrics Pro 的 AI 助手背後的理念——讓數據對所有人都好懂，不管技術背景。」

---

## 問題 19：你在 A/B 測試和實驗方面的方法是什麼？

**答案（< 60 秒）：**

「從正確的實驗設計開始。清楚定義假設、成功指標、最小可檢測效應、統計功效、樣本大小，在啟動前。對隨機化小心避免選擇偏差。確保對照組和處理組真正可比。

實驗期間，監控 bug 或實施問題但避免太早偷看防止假陽性。分析用適當的統計檢驗——連續指標像收入用 t 檢驗，分類指標像轉換用卡方檢驗。

永遠檢查統計顯著性和實際顯著性。統計顯著的 0.5% 提升可能不值得工程努力。也對結果分群——整體贏可能對某些用戶群是輸。

在 Farmz Asia，對訊息、登陸頁、郵件持續跑 A/B 測試。提升參與度 58%。對 Jobscan 我想建一個實驗框架讓測試定價變化、功能變體、入門流程變容易。正確的隨機化、統計嚴謹、自動報告。目標是讓實驗變核心能力，不是一次性專案。」

---

## 問題 20：你為什麼特別想在 Jobscan 工作？

**答案（< 60 秒）：**

「老實說多個原因。第一，使命共鳴。你們幫 200 萬求職者拿到面試、改變職涯。那是真實影響。我經歷過求職那面。我知道沒有對的工具有多殘酷。

第二，職位本身——直接跟 CEO 合作，為行銷、產品、銷售建關鍵商業智能，成為戰略決策的真相來源。那是我想要的影響。

第三，技術挑戰讓我興奮。整合分散的數據源——Stripe、GA、MySQL、聯盟網絡。複雜、重要的工作。

第四，你們是客戶資助且盈利的。代表你在建人們真正重視的東西。業務是可持續的。

第五，遠程彈性文化、無限 PTO、學習津貼。顯示你投資在人身上。

最後——我特別建了 JobMetrics Pro 來證明我懂你商業模式而且能立刻上手。我字面上設計了你需要的分析儀表板。我懂 SaaS 經濟學。我有行銷分析背景。我帶現代技能像 AI 整合。這不只是另一份工作——這是我技能、經驗、熱情都對齊的地方。」

---

## 結束註記

**Jerry 語氣元素應用：**
- ✅ 對話式，不是獨白（感覺像在活躍對話）
- ✅ 快節奏「去。給我看。原因是這個。」
- ✅ 富含情境與真實利害關係（「1200 萬美金」「5 萬人」）
- ✅ 邊想邊說（「就是，我在乎...」「因為那八成是...」）
- ✅ 兩種模式：高效操作者 + 誠實反思
- ✅ 台灣/LA 隨性語調（「有點特別」「老實說」「你看」）
- ✅ 避開 AI/企業死板字眼（沒有「綜效」「槓桿」「利用」）
- ✅ 透明處理過程（「重點是」「但等等」）
- ✅ 節奏很重要（短有力句子混合流暢段落）

**所有答案在 Jerry 自然語速下 < 60 秒**

---

**練習技巧：**
1. 大聲讀出來內化節奏
2. 不要逐字背誦 - 內化結構
3. 如果面試官打斷追問，那很好 - 你進入對話模式了
4. 用手勢、身體前傾、展現你在場
5. 如果忘了接下來講什麼，就說「等等讓我想想」- 很真實

**加油 Jerry。你可以的。** 🚀
